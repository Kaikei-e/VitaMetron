# MLモデル自動再トレーニングスケジューラの導入

## ADR's STATUS

採用済み (2026-02-25)

## CONTEXT

本システムでは 3 つの ML モデル（Anomaly / HRV / Divergence）を使用しているが、トレーニングは手動 POST エンドポイント経由のみだった。新データが蓄積されてもモデルは古いまま放置され、個人の体調変化（概念ドリフト）にモデルが追従できない状態だった。

### 各モデルのデータ依存性

| モデル | アルゴリズム | 最低データ | 計算コスト |
|---|---|---|---|
| Anomaly | Isolation Forest + POT | 30 valid days | 数秒 |
| HRV | XGBoost + LSTM Ensemble | 90 valid days | Optuna 50 試行: 10-30 分 / 固定 params: 2-5 分 |
| Divergence | Ridge + CuSum | 14 paired obs | ミリ秒 |

### 再トレーニングの動機

- **概念ドリフト**: HRV の日次変動係数は 25-29% と大きく、データドリフトよりも体力レベル変化・疾病・投薬変更などによる概念ドリフトが主な再トレーニング動機
- **N-of-1 パーソナライゼーション**: 単一ユーザーシステムのため、新データの蓄積は常にモデル改善に寄与する
- **Isolation Forest と概念ドリフト**: 新データが「正常」の分布を変える可能性があり、POT 閾値の再較正が有効

## DECISION MAKING

### 検討した選択肢

| 選択肢 | 概要 | 評価 |
|---|---|---|
| A. 2 段階スケジューラ（日次軽量 + 週次完全） | 日次は固定パラメータで再トレーニング、週次で Optuna 全探索 + LSTM | ✅ 採用 |
| B. 日次で毎回完全再トレーニング | 毎日 Optuna + LSTM を実行 | × 1 日分の新データでは HP 変化が統計的に無意味。計算資源の浪費 |
| C. ドリフト検出時のみ再トレーニング | anomaly rate 閾値ベースのトリガー | △ 実装が複雑で、ドリフト検出自体の精度が不確実 |
| D. 週次のみ | 週 1 回の完全再トレーニング | △ Anomaly/Divergence は計算コストが極小なので日次で問題ない。新 condition_log の即反映も重要 |

### 選択肢 A を採用した理由

- **統計的根拠**: 1 日分の新データではハイパーパラメータは有意に変化しないため、日次では Optuna をスキップし前回の best_params を再利用するのが効率的
- **計算コストの最適化**: Anomaly/Divergence は計算コストが極小のため日次で全データ再トレーニングしても問題ない。HRV のみ日次/週次で戦略を分ける
- **固定スケジュール + ドリフト検出のハイブリッドが推奨される中、まず固定スケジュールを導入し、将来的にドリフト検出を追加可能な設計とした

### 2 段階再トレーニング戦略

#### 日次軽量再トレーニング（毎日 03:00）

| モデル | 動作 | 根拠 |
|---|---|---|
| Anomaly | 全データで再トレーニング | 計算コスト極小。POT 閾値の再較正が有効 |
| HRV | 前回の best_params を使用して XGBoost 再トレーニング（Optuna スキップ、LSTM スキップ） | 1 日分の新データでは HP 変化は統計的に無意味 |
| Divergence | 全ペアデータで再トレーニング | 計算コスト極小。新しい condition_log の即反映が重要 |

#### 週次完全再トレーニング（毎週月曜 03:00）

| モデル | 動作 | 根拠 |
|---|---|---|
| Anomaly | 全データで再トレーニング | 同上 |
| HRV | Optuna 全探索 + LSTM 再トレーニング + Ensemble 最適化 | 7 日分の蓄積で HP 探索が統計的に有意 |
| Divergence | 全ペアデータで再トレーニング | 同上 |

### トレーニング可否判定ロジック（3 段階チェック）

各モデルに対してトレーニング前に以下を検証し、不要・不適切な再トレーニングを防止する:

1. **データ充足性**: Anomaly >= 30 日、HRV >= 90 日（HRV ターゲット非 NULL）、Divergence >= 14 ペア
2. **新データ蓄積**: 前回トレーニング以降に新しい有効データが 0 件なら skip（同一データでの再トレーニングは無意味）
3. **直近データ品質**: 直近 7 日で valid_days < 3 または avg_completeness < 40% ならスキップ（Fitbit 未装着期間のノイズデータでの再トレーニングを防止）

### アーキテクチャ設計

トレーニングロジックをルーターから分離し、再利用可能な関数として `ml/app/training/` パッケージに抽出した。これにより:

- 手動トレーニング（POST エンドポイント）とスケジュール実行が同じコードパスを共有
- テスタビリティが向上（ルーターの HTTP 層とトレーニングロジックを独立してテスト可能）
- `retrain_logs` テーブルで実行履歴を監査可能

## RESULTS, EFFECTS

### PROS

- **モデルが自動的に最新データに追従**: 毎日のデータ蓄積が翌日 03:00 にモデルへ反映される
- **HRV の計算コスト最適化**: 日次は固定パラメータ（2-5 分）、週次のみ Optuna 全探索（10-30 分）
- **安全な再トレーニング**: 3 段階チェックにより、データ不足・新データなし・品質低下時は自動スキップ
- **手動トリガーも可能**: `POST /api/retrain/trigger` で任意のタイミングで daily/weekly モードを手動実行可能
- **監査ログ**: `retrain_logs` テーブルに全実行の結果・所要時間・各モデルのステータスが記録される
- **既存 API との互換性**: 既存の手動 POST `/anomaly/train`, `/hrv/train`, `/divergence/train` は引き続き動作する

### CONS, TRADEOFF

- **APScheduler 依存の追加**: `apscheduler>=3.10,<4` を新規依存として追加。APScheduler v4 は非互換のため上限を設定
- **月曜日のジョブ重複回避**: 日次ジョブが月曜日を検出してスキップするロジックが必要（週次が日次を包含するため）
- **HRV daily モードの精度**: 前回の best_params を固定で使用するため、データ分布が大きく変化した場合に最適でない可能性がある（週次で補正される）
- **単一プロセス内スケジューラ**: ML サービスが複数インスタンスにスケールした場合、ジョブが重複実行される。現在は単一ユーザー・単一インスタンスのため問題ないが、将来的にはロック機構が必要

## APPENDIX

### 変更ファイル

| ファイル | 変更内容 |
|---|---|
| `ml/app/training/__init__.py` | 新規: トレーニングパッケージ |
| `ml/app/training/errors.py` | 新規: `InsufficientDataError`, `NoNewDataError`, `LowQualityDataError` |
| `ml/app/training/anomaly.py` | 新規: `train_anomaly()` 関数 |
| `ml/app/training/hrv.py` | 新規: `train_hrv()` 関数（`optuna_trials=0` で日次モード対応） |
| `ml/app/training/divergence.py` | 新規: `train_divergence()` 関数 |
| `ml/app/training/checks.py` | 新規: 3 段階トレーニング可否判定 |
| `ml/app/retrain.py` | 新規: 再トレーニングオーケストレーター |
| `ml/app/scheduler.py` | 新規: APScheduler による日次/週次 cron |
| `ml/app/schemas/retrain.py` | 新規: レスポンススキーマ |
| `ml/app/routers/retrain.py` | 新規: `/retrain/check`, `/retrain/trigger`, `/retrain/status`, `/retrain/logs` |
| `ml/app/routers/anomaly.py` | 変更: 抽出関数を呼び出すようリファクタ |
| `ml/app/routers/hrv_predict.py` | 変更: 同上 |
| `ml/app/routers/divergence.py` | 変更: 同上 |
| `ml/app/main.py` | 変更: スケジューラ起動/停止 + retrain ルーター登録 |
| `ml/app/config.py` | 変更: `retrain_enabled`, `retrain_daily_hour`, `retrain_daily_minute`, `retrain_weekly_day` 追加 |
| `ml/pyproject.toml` | 変更: `apscheduler>=3.10,<4` 追加 |
| `api/infrastructure/database/migrations/20260225110432_add_retrain_logs.sql` | 新規: `retrain_logs` テーブル |
| `api/domain/entity/retrain.go` | 新規: ドメインエンティティ |
| `api/handler/retrain.go` | 新規: Go API ハンドラ |
| `api/adapter/mlclient/client.go` | 変更: retrain 用メソッド 4 つ追加 |
| `api/cmd/server/main.go` | 変更: retrainHandler の DI 追加 |
| `nginx/nginx.conf` | 変更: `retrain/trigger` を長時間タイムアウト対象に追加 |

### テスト

| テストファイル | テスト数 | 対象 |
|---|---|---|
| `ml/tests/test_training_checks.py` | 9 | トレーニング可否判定の 3 段階チェック |
| `ml/tests/test_retrain.py` | 5 | オーケストレーション（skip/success/error/daily/weekly） |
| `ml/tests/test_retrain_router.py` | 5 | HTTP エンドポイント |
| `ml/tests/test_scheduler.py` | 5 | スケジューラ設定 |

### API エンドポイント

| メソッド | パス | 用途 |
|---|---|---|
| GET | `/api/retrain/check` | 全モデルのトレーニング可否チェック |
| POST | `/api/retrain/trigger` | 手動トリガー（`{"mode": "daily"}` or `{"mode": "weekly"}`） |
| GET | `/api/retrain/status` | 最新の再トレーニング結果 |
| GET | `/api/retrain/logs?limit=10&offset=0` | 再トレーニング履歴 |

### スケジュール設定（環境変数で変更可能）

| 設定 | デフォルト | 説明 |
|---|---|---|
| `RETRAIN_ENABLED` | `true` | スケジューラの有効/無効 |
| `RETRAIN_DAILY_HOUR` | `3` | 日次実行時刻（時） |
| `RETRAIN_DAILY_MINUTE` | `0` | 日次実行時刻（分） |
| `RETRAIN_WEEKLY_DAY` | `mon` | 週次実行曜日 |
